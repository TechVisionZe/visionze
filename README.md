<div align="center">
  <p>
    <a align="center" href="" target="_blank">
      <img
        width="850"
        src="https://raw.githubusercontent.com/roboflow/notebooks/main/assets/roboflow-notebooks-banner.png"
      >
    </a>
  </p>
  <br>

  [notebooks](https://github.com/roboflow/notebooks) | [inference](https://github.com/roboflow/inference) | [autodistill](https://github.com/autodistill/autodistill) | [RF-DETR](https://github.com/roboflow/rf-detr)

  <br>

  <div align="center">
      <a href="https://youtube.com/roboflow">
          <img
            src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672949634652"
            width="3%"
          />
      </a>
      <img src="https://github.com/SkalskiP/SkalskiP/blob/master/icons/transparent.png" width="3%"/>
      <a href="https://roboflow.com">
          <img
            src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672949746649"
            width="3%"
          />
      </a>
      <img src="https://github.com/SkalskiP/SkalskiP/blob/master/icons/transparent.png" width="3%"/>
      <a href="https://www.linkedin.com/company/roboflow-ai/">
          <img
            src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672949633691"
            width="3%"
          />
      </a>
      <img src="https://github.com/SkalskiP/SkalskiP/blob/master/icons/transparent.png" width="3%"/>
      <a href="https://docs.roboflow.com">
          <img
            src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672949634511"
            width="3%"
          />
      </a>
      <img src="https://github.com/SkalskiP/SkalskiP/blob/master/icons/transparent.png" width="3%"/>
      <a href="https://discuss.roboflow.com">
          <img
            src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672949633584"
            width="3%"
          />
      <img src="https://github.com/SkalskiP/SkalskiP/blob/master/icons/transparent.png" width="3%"/>
      <a href="https://blog.roboflow.com">
          <img
            src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672949633605"
            width="3%"
          />
      </a>
      </a>
  </div>

</div>

## üëã hello

This repository offers a growing collection of computer vision tutorials. Learn to use SOTA models like YOLOv11, SAM 2, Florence-2, PaliGemma 2, and Qwen2.5-VL for tasks ranging from object detection, segmentation, and pose estimation to data extraction and OCR. Dive in and explore the exciting world of computer vision!

<!--- AUTOGENERATED-NOTEBOOKS-TABLE -->
<!---
   WARNING: DO NOT EDIT THIS TABLE MANUALLY. IT IS AUTOMATICALLY GENERATED.
   HEAD OVER TO CONTRIBUTING.MD FOR MORE DETAILS ON HOW TO MAKE CHANGES PROPERLY.
-->
# üöÄ AI Model Tutorials (50+ Notebooks)
*‚ú® One-click notebooks | Latest models | Performance benchmarks | Community favorites*

## üèÜ Featured Tutorials

| Model | Task | Difficulty | Platforms | Resources | Metrics |
|-------|------|------------|-----------|-----------|---------|
| **[RF-DETR](https://github.com/roboflow-ai/notebooks)**<br>State-of-the-art transformer detection | üéØ Object Detection | ‚≠ê‚≠ê | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels) | üìù [Blog](https://blog.roboflow.com/rf-detr)<br>üíª [GitHub](https://github.com/roboflow/rf-detr) | 92% Accuracy<br>2h Training |
| **[YOLOv12](https://github.com/roboflow-ai/notebooks)**<br>Ultra-fast detection | üéØ Object Detection | ‚≠ê‚≠ê | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels) | üìù [Benchmarks](https://blog.roboflow.com/yolov12)<br>üõ†Ô∏è [GitHub](https://github.com/sunsmarterjie/yolov12) | 8ms Latency<br>1.2K Votes |
| **[PaliGemma2](https://github.com/roboflow-ai/notebooks)**<br>Google's vision model | üåç Multimodal AI | ‚≠ê‚≠ê‚≠ê‚≠ê | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks) [![SageMaker](https://img.shields.io/badge/SageMaker-FF9900?logo=amazonaws&logoColor=white)](https://studiolab.sagemaker.aws) | üìù [Case Study](https://blog.roboflow.com/paligemma2)<br>üîß [GitHub](https://github.com/google-research/big_vision) | 89% VQA Acc<br>#1 Trending |

## üîç Tutorials by Category

| Category        | Tutorial | Platforms | Resources |
|-----------------|----------|-----------|-----------|
| **üéØ Object Detection** | [Fine-Tune YOLOv10](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-yolov10-object-detection-on-custom-dataset.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov10-object-detection-on-custom-dataset.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-yolov10-object-detection-on-custom-dataset.ipynb) | [üìù Blog](https://blog.roboflow.com/yolov10-how-to-train/) ‚Ä¢ [üíª GitHub](https://github.com/THU-MIG/yolov10) |
| | [Fine-Tune RT-DETR](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-rt-detr-on-custom-dataset-with-transformers.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-rt-detr-on-custom-dataset-with-transformers.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-rt-detr-on-custom-dataset-with-transformers.ipynb) | [üìù Blog](https://blog.roboflow.com/train-rt-detr-custom-dataset-transformers/) ‚Ä¢ [üíª GitHub](https://github.com/lyuwenyu/RT-DETR) |
| | [Fine-Tune Florence-2](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-florence-2-on-detection-dataset.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-florence-2-on-detection-dataset.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-florence-2-on-detection-dataset.ipynb) | [üìù Blog](https://blog.roboflow.com/fine-tune-florence-2-object-detection/) ‚Ä¢ [‚ñ∂Ô∏è Video](https://youtu.be/i3KjYgxNH6w) |
| **üñºÔ∏è Segmentation** | [Segment with SAM-2](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-segment-images-with-sam-2.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-segment-images-with-sam-2.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-segment-images-with-sam-2.ipynb) | [üìù Blog](https://blog.roboflow.com/what-is-segment-anything-2/) ‚Ä¢ [üíª GitHub](https://github.com/facebookresearch/segment-anything-2) |
| | [Fine-Tune SAM-2.1](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/fine-tune-sam-2.1.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/fine-tune-sam-2.1.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/fine-tune-sam-2.1.ipynb) | [üìù Blog](https://blog.roboflow.com/fine-tune-sam-2-1/) ‚Ä¢ [‚ñ∂Ô∏è Video](https://youtu.be/QnCGcFHZy9s) |
| **üìÑ Document AI** | [Qwen-VL Data Extraction](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-qwen2-5-vl-for-json-data-extraction.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-qwen2-5-vl-for-json-data-extraction.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-qwen2-5-vl-for-json-data-extraction.ipynb) | [‚ñ∂Ô∏è Video](https://youtu.be/xEfh0IR8Fvo) ‚Ä¢ [üíª GitHub](https://github.com/QwenLM/Qwen2.5-VL) |
| | [PaliGemma2 for LaTeX OCR](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-paligemma2-on-latex-ocr-dataset.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-paligemma2-on-latex-ocr-dataset.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-paligemma2-on-latex-ocr-dataset.ipynb) | [üìù Blog](https://blog.roboflow.com/fine-tune-paligemma-2/) ‚Ä¢ [üíª GitHub](https://github.com/google-research/big_vision) |

## üåü New Releases
| Model | Highlights | 
|-------|------------|
| **[GPT-4o](https://github-link)** | OpenAI's multimodal model for detection |
| **[YOLO11](https://github-link)** | Latest YOLO architecture |
| **[SAM-2](https://github-link)** | Meta's advanced segmentation |

<div style="text-align: center; margin: 30px 0;">
  <a href="https://github.com/roboflow-ai/notebooks" style="display: inline-block; background: linear-gradient(90deg, #6e48aa 0%, #9d50bb 100%); color: white; padding: 12px 30px; border-radius: 30px; text-decoration: none; font-weight: bold; font-size: 1.1em;">
    Explore All Notebooks on GitHub ‚Üí
  </a>
</div>

## üì∏ computer vision skills (21 notebooks)
| **notebook** | **open in colab / kaggle / sagemaker studio lab** | **complementary materials** | **repository / paper** |
|:------------:|:-------------------------------------------------:|:---------------------------:|:----------------------:|
| [Football AI](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/football-ai.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/football-ai.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/football-ai.ipynb)  | [![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/camera-calibration-sports-computer-vision/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/aBVGKoNZQUw) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/roboflow/sports) |
| [Auto-Annotate Dataset with GroundedSAM 2](https://github.com/roboflow-ai/notebooks/blob/main/notebooks/grounded-sam-2-auto-label.ipynb) | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/grounded-sam-2-auto-label.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/roboflow-ai/notebooks/blob/main/notebooks/grounded-sam-2-auto-label.ipynb)  | [![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/what-is-segment-anything-2)  | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/facebookresearch/segment-anything-2) |


## üé¨ videos

Almost every week we create tutorials showing you the hottest models in Computer Vision. üî•
[Subscribe](https://www.youtube.com/@Roboflow), and stay up to date with our latest YouTube videos!

<p align="left">
<a href="https://youtu.be/CilXrt3S-ws" title="How to Choose the Best Computer Vision Model for Your Project"><img src="https://github.com/roboflow/notebooks/assets/26109316/73a01d3b-cf70-40c3-a5e4-e4bc5be38d42" alt="How to Choose the Best Computer Vision Model for Your Project" width="300px" align="left" /></a>
<a href="https://youtu.be/CilXrt3S-ws" title="How to Choose the Best Computer Vision Model for Your Project"><strong>How to Choose the Best Computer Vision Model for Your Project</strong></a>
<div><strong>Created: 26 May 2023</strong> | <strong>Updated: 26 May 2023</strong></div>
<br/> In this video, we will dive into the complexity of choosing the right computer vision model for your unique project. From the importance of high-quality datasets to hardware considerations, interoperability, benchmarking, and licensing issues, this video covers it all... </p> <br/>

<p align="left">
<a href="https://youtu.be/oEQYStnF2l8" title="Accelerate Image Annotation with SAM and Grounding DINO"><img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/ae1ca38e-40b7-4b35-8582-e8ea5de3806e" alt="Accelerate Image Annotation with SAM and Grounding DINO" width="300px" align="left" /></a>
<a href="https://youtu.be/oEQYStnF2l8" title="Accelerate Image Annotation with SAM and Grounding DINO"><strong>Accelerate Image Annotation with SAM and Grounding DINO</strong></a>
<div><strong>Created: 20 Apr 2023</strong> | <strong>Updated: 20 Apr 2023</strong></div>
<br/> Discover how to speed up your image annotation process using Grounding DINO and Segment Anything Model (SAM). Learn how to convert object detection datasets into instance segmentation datasets, and see the potential of using these models to automatically annotate your datasets for real-time detectors like YOLOv8... </p> <br/>
<p align="left">
<a href="https://youtu.be/D-D6ZmadzPE" title="SAM - Segment Anything Model by Meta AI: Complete Guide"><img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/6913ff11-53c6-4341-8d90-eaff3023c3fd" alt="SAM - Segment Anything Model by Meta AI: Complete Guide" width="300px" align="left" /></a>
<a href="https://youtu.be/D-D6ZmadzPE" title="SAM - Segment Anything Model by Meta AI: Complete Guide"><strong>SAM - Segment Anything Model by Meta AI: Complete Guide</strong></a>
<div><strong>Created: 11 Apr 2023</strong> | <strong>Updated: 11 Apr 2023</strong></div>

<br/> Discover the incredible potential of Meta AI's Segment Anything Model (SAM)! We dive into SAM, an efficient and promptable model for image segmentation, which has revolutionized computer vision tasks. With over 1 billion masks on 11M licensed and privacy-respecting images, SAM's zero-shot performance is often superior to prior fully supervised results... </p>

## üíª run locally

We try to make it as easy as possible to run Roboflow Notebooks in Colab and Kaggle, but if you still want to run them
locally, below you will find instructions on how to do it. Remember don't install your dependencies globally, use
[venv](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/).

```console
# clone repository and navigate to root directory
git clone git@github.com:roboflow-ai/notebooks.git
cd notebooks

# setup python environment and activate it
python3 -m venv venv
source venv/bin/activate

# install and run jupyter notebook
pip install notebook
jupyter notebook
```

## ‚òÅÔ∏è run in sagemaker studio lab

You can now open our tutorial notebooks in [Amazon SageMaker Studio Lab](https://aws.amazon.com/sagemaker/studio-lab/) -
a free machine learning development environment that provides the compute, storage, and security‚Äîall at no cost‚Äîfor
anyone to learn and experiment with ML.

| Stable Diffusion Image Generation | YOLOv5 Custom Dataset Training | YOLOv7 Custom Dataset Training |
|:---------------------------------:|:------------------------------:|:------------------------------:|
|  [![SageMaker](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/sage-maker.svg)](https://studiolab.sagemaker.aws/import/github/roboflow-ai/notebooks/blob/main/notebooks/sagemaker-studiolab/stable-diffusion-image-generation.ipynb) | [![SageMaker](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/sage-maker.svg)](https://studiolab.sagemaker.aws/import/github/roboflow-ai/notebooks/blob/main/notebooks/sagemaker-studiolab/yolov5-custom-training.ipynb)       |[![SageMaker](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/sage-maker.svg)](https://studiolab.sagemaker.aws/import/github/roboflow-ai/notebooks/blob/main/notebooks/sagemaker-studiolab/yolov7-custom-training.ipynb)       |


## üêû bugs & ü¶∏ contribution

Computer Vision moves fast! Sometimes our notebooks lag a tad behind the ever-pushing
forward libraries. If you notice that any of the notebooks is not working properly, create a
[bug report](https://github.com/roboflow-ai/notebooks/issues/new?assignees=&labels=bug%2Ctriage&template=bug-report.yml)
and let us know.

If you have an idea for a new tutorial we should do, create a
[feature request](https://github.com/roboflow-ai/notebooks/issues/new?assignees=&labels=enhancement&template=feature-request.yml).
We are constantly looking for new ideas. If you feel up to the task and want to create a tutorial yourself, please take
a peek at our [contribution guide](https://github.com/roboflow-ai/notebooks/blob/main/CONTRIBUTING.md). There you can
find all the information you need.

We are here for you, so don't hesitate to [reach out](https://github.com/roboflow-ai/notebooks/discussions).
